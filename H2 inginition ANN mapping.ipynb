{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cantera version: 2.4.0a1\n"
     ]
    }
   ],
   "source": [
    "from reactor_ode_test import states\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAEKCAYAAACG4YuJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b5b477375c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L1 = plt.plot(states.T, color='r', label='T', lw=2)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.twinx()\n",
    "# L2 = plt.plot(states.t, states('OH').Y, label='OH', lw=2)\n",
    "L2 = plt.plot(states('OH').Y, label='OH', lw=2)\n",
    "plt.ylabel('Mass Fraction')\n",
    "plt.legend(L1 + L2, [line.get_label() for line in L1 + L2], loc='lower right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_floatx('float32')\n",
    "print(K.floatx())\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, BatchNormalization, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from res_block import res_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cantera version: 2.4.0a1\n",
      "H2\n",
      "H\n",
      "O2\n",
      "OH\n",
      "O\n",
      "H2O\n",
      "HO2\n",
      "H2O2\n",
      "N2\n",
      "temperature\n",
      "H2\n",
      "H\n",
      "O2\n",
      "OH\n",
      "O\n",
      "H2O\n",
      "HO2\n",
      "H2O2\n",
      "N2\n",
      "temperature\n"
     ]
    }
   ],
   "source": [
    "from reactor_ode import train_org, train_new, train_res\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "# prepare data\n",
    "# train_org = train_org[0.000:0.001]\n",
    "# train_new = train_new[0.000:0.001]\n",
    "# train_org, train_new = shuffle(train_org, train_new)\n",
    "\n",
    "output = train_org.columns\n",
    "label_values = []\n",
    "input_norm_scalers = {}\n",
    "input_std_scalers = {}\n",
    "for itm in output:\n",
    "    print(itm)\n",
    "    norm_scaler = MinMaxScaler()\n",
    "    std_scaler = StandardScaler()\n",
    "    # same input_label scaler\n",
    "    # std_scaler.fit(np.concatenate([train_org[itm], train_new[itm]], axis=0).reshape(-1, 1))\n",
    "    # out = std_scaler.transform(train_org[itm].values.reshape(-1, 1))\n",
    "    # input scaler\n",
    "    out = std_scaler.fit_transform(train_org[itm].values.reshape(-1, 1))\n",
    "    # out = out/out.max()\n",
    "    out = 2 * norm_scaler.fit_transform(out) - 1\n",
    "\n",
    "    label_values.append(out)\n",
    "    input_norm_scalers[itm] = norm_scaler\n",
    "    input_std_scalers[itm] = std_scaler\n",
    "\n",
    "x_train = np.concatenate(\n",
    "    label_values,\n",
    "    axis=1)\n",
    "\n",
    "output = train_new.columns\n",
    "# output = ['H2']\n",
    "label_values = []\n",
    "label_norm_scalers = {}\n",
    "label_std_scalers = {}\n",
    "for itm in output:\n",
    "    print(itm)\n",
    "    # same input_label scaler\n",
    "    # out = input_std_scalers[itm].transform(train_new[itm].values.reshape(-1, 1))\n",
    "    # input scaler\n",
    "    norm_scaler = MinMaxScaler()\n",
    "    std_scaler = StandardScaler()\n",
    "    # out = train_new[itm].values.reshape(-1, 1)\n",
    "    out = std_scaler.fit_transform(train_new[itm].values.reshape(-1, 1))\n",
    "    # out = out-out.min()\n",
    "    out = 2 * norm_scaler.fit_transform(out) - 1\n",
    "\n",
    "    label_values.append(out)\n",
    "    label_norm_scalers[itm] = norm_scaler\n",
    "    label_std_scalers[itm] = std_scaler\n",
    "\n",
    "y_train = np.concatenate(\n",
    "    label_values,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up ANN\n",
      "<dtype: 'float32'>\n",
      "Train on 8987 samples, validate on 999 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 0.7125 - acc: 0.2899 - val_loss: 0.6375 - val_acc: 0.0030\n",
      "Epoch 2/500\n",
      "0s - loss: 0.2963 - acc: 0.6316 - val_loss: 0.4746 - val_acc: 0.5315\n",
      "Epoch 3/500\n",
      "0s - loss: 0.2083 - acc: 0.7249 - val_loss: 0.4171 - val_acc: 0.5315\n",
      "Epoch 4/500\n",
      "0s - loss: 0.1714 - acc: 0.7821 - val_loss: 0.3688 - val_acc: 0.5315\n",
      "Epoch 5/500\n",
      "0s - loss: 0.1439 - acc: 0.8081 - val_loss: 0.3206 - val_acc: 0.4194\n",
      "Epoch 6/500\n",
      "0s - loss: 0.1258 - acc: 0.8069 - val_loss: 0.2801 - val_acc: 0.4194\n",
      "Epoch 7/500\n",
      "0s - loss: 0.1168 - acc: 0.8295 - val_loss: 0.2731 - val_acc: 0.4194\n",
      "Epoch 8/500\n",
      "0s - loss: 0.1081 - acc: 0.8385 - val_loss: 0.2495 - val_acc: 0.4224\n",
      "Epoch 9/500\n",
      "0s - loss: 0.0957 - acc: 0.8395 - val_loss: 0.2317 - val_acc: 0.4244\n",
      "Epoch 10/500\n",
      "Epoch 00009: val_loss improved from inf to 0.20402, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0941 - acc: 0.8429 - val_loss: 0.2040 - val_acc: 0.4304\n",
      "Epoch 11/500\n",
      "0s - loss: 0.0917 - acc: 0.8553 - val_loss: 0.2107 - val_acc: 0.4324\n",
      "Epoch 12/500\n",
      "0s - loss: 0.0879 - acc: 0.8601 - val_loss: 0.1970 - val_acc: 0.5475\n",
      "Epoch 13/500\n",
      "0s - loss: 0.0757 - acc: 0.8649 - val_loss: 0.1728 - val_acc: 0.5566\n",
      "Epoch 14/500\n",
      "0s - loss: 0.0753 - acc: 0.8589 - val_loss: 0.1609 - val_acc: 0.5636\n",
      "Epoch 15/500\n",
      "0s - loss: 0.0692 - acc: 0.8802 - val_loss: 0.1556 - val_acc: 0.5716\n",
      "Epoch 16/500\n",
      "0s - loss: 0.0655 - acc: 0.8739 - val_loss: 0.1437 - val_acc: 0.5786\n",
      "Epoch 17/500\n",
      "0s - loss: 0.0636 - acc: 0.8747 - val_loss: 0.1380 - val_acc: 0.5756\n",
      "Epoch 18/500\n",
      "0s - loss: 0.0722 - acc: 0.8814 - val_loss: 0.1424 - val_acc: 0.5806\n",
      "Epoch 19/500\n",
      "0s - loss: 0.0639 - acc: 0.8784 - val_loss: 0.1388 - val_acc: 0.5866\n",
      "Epoch 20/500\n",
      "Epoch 00019: val_loss improved from 0.20402 to 0.12669, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0603 - acc: 0.8828 - val_loss: 0.1267 - val_acc: 0.5876\n",
      "Epoch 21/500\n",
      "0s - loss: 0.0582 - acc: 0.8925 - val_loss: 0.1154 - val_acc: 0.5976\n",
      "Epoch 22/500\n",
      "0s - loss: 0.0535 - acc: 0.8877 - val_loss: 0.1008 - val_acc: 0.6106\n",
      "Epoch 23/500\n",
      "0s - loss: 0.0541 - acc: 0.8843 - val_loss: 0.0982 - val_acc: 0.6036\n",
      "Epoch 24/500\n",
      "0s - loss: 0.0538 - acc: 0.8963 - val_loss: 0.0845 - val_acc: 0.6276\n",
      "Epoch 25/500\n",
      "0s - loss: 0.0533 - acc: 0.8982 - val_loss: 0.1000 - val_acc: 0.6296\n",
      "Epoch 26/500\n",
      "0s - loss: 0.0658 - acc: 0.8969 - val_loss: 0.0926 - val_acc: 0.6366\n",
      "Epoch 27/500\n",
      "0s - loss: 0.0499 - acc: 0.9056 - val_loss: 0.0770 - val_acc: 0.6196\n",
      "Epoch 28/500\n",
      "0s - loss: 0.0485 - acc: 0.8857 - val_loss: 0.0740 - val_acc: 0.6366\n",
      "Epoch 29/500\n",
      "0s - loss: 0.0489 - acc: 0.8960 - val_loss: 0.0755 - val_acc: 0.6266\n",
      "Epoch 30/500\n",
      "Epoch 00029: val_loss improved from 0.12669 to 0.08772, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0521 - acc: 0.8958 - val_loss: 0.0877 - val_acc: 0.6096\n",
      "Epoch 31/500\n",
      "0s - loss: 0.0497 - acc: 0.8960 - val_loss: 0.0691 - val_acc: 0.6186\n",
      "Epoch 32/500\n",
      "0s - loss: 0.0455 - acc: 0.8972 - val_loss: 0.0699 - val_acc: 0.6276\n",
      "Epoch 33/500\n",
      "0s - loss: 0.0418 - acc: 0.8984 - val_loss: 0.0648 - val_acc: 0.6286\n",
      "Epoch 34/500\n",
      "0s - loss: 0.0432 - acc: 0.9070 - val_loss: 0.0758 - val_acc: 0.6396\n",
      "Epoch 35/500\n",
      "0s - loss: 0.0420 - acc: 0.9027 - val_loss: 0.0642 - val_acc: 0.6456\n",
      "Epoch 36/500\n",
      "0s - loss: 0.0375 - acc: 0.9058 - val_loss: 0.0725 - val_acc: 0.6396\n",
      "Epoch 37/500\n",
      "0s - loss: 0.0405 - acc: 0.8932 - val_loss: 0.0591 - val_acc: 0.6527\n",
      "Epoch 38/500\n",
      "0s - loss: 0.0366 - acc: 0.9050 - val_loss: 0.0706 - val_acc: 0.4484\n",
      "Epoch 39/500\n",
      "0s - loss: 0.0399 - acc: 0.9059 - val_loss: 0.0608 - val_acc: 0.6517\n",
      "Epoch 40/500\n",
      "Epoch 00039: val_loss improved from 0.08772 to 0.06133, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0429 - acc: 0.9098 - val_loss: 0.0613 - val_acc: 0.6436\n",
      "Epoch 41/500\n",
      "0s - loss: 0.0417 - acc: 0.9147 - val_loss: 0.0592 - val_acc: 0.6466\n",
      "Epoch 42/500\n",
      "0s - loss: 0.0397 - acc: 0.9112 - val_loss: 0.0689 - val_acc: 0.6396\n",
      "Epoch 43/500\n",
      "0s - loss: 0.0371 - acc: 0.9104 - val_loss: 0.0667 - val_acc: 0.6466\n",
      "Epoch 44/500\n",
      "0s - loss: 0.0362 - acc: 0.9131 - val_loss: 0.0573 - val_acc: 0.6537\n",
      "Epoch 45/500\n",
      "0s - loss: 0.0360 - acc: 0.9169 - val_loss: 0.0544 - val_acc: 0.6507\n",
      "Epoch 46/500\n",
      "0s - loss: 0.0344 - acc: 0.9148 - val_loss: 0.0571 - val_acc: 0.6226\n",
      "Epoch 47/500\n",
      "0s - loss: 0.0343 - acc: 0.9219 - val_loss: 0.0507 - val_acc: 0.6456\n",
      "Epoch 48/500\n",
      "0s - loss: 0.0334 - acc: 0.9208 - val_loss: 0.0531 - val_acc: 0.6446\n",
      "Epoch 49/500\n",
      "0s - loss: 0.0348 - acc: 0.9137 - val_loss: 0.0576 - val_acc: 0.6446\n",
      "Epoch 50/500\n",
      "Epoch 00049: val_loss improved from 0.06133 to 0.05068, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0320 - acc: 0.9171 - val_loss: 0.0507 - val_acc: 0.6537\n",
      "Epoch 51/500\n",
      "0s - loss: 0.0293 - acc: 0.9128 - val_loss: 0.0514 - val_acc: 0.6527\n",
      "Epoch 52/500\n",
      "0s - loss: 0.0306 - acc: 0.9203 - val_loss: 0.0627 - val_acc: 0.6426\n",
      "Epoch 53/500\n",
      "0s - loss: 0.0341 - acc: 0.9203 - val_loss: 0.0594 - val_acc: 0.6336\n",
      "Epoch 54/500\n",
      "0s - loss: 0.0311 - acc: 0.9165 - val_loss: 0.0665 - val_acc: 0.6366\n",
      "Epoch 55/500\n",
      "0s - loss: 0.0321 - acc: 0.9142 - val_loss: 0.0624 - val_acc: 0.6346\n",
      "Epoch 56/500\n",
      "0s - loss: 0.0300 - acc: 0.9162 - val_loss: 0.0503 - val_acc: 0.6537\n",
      "Epoch 57/500\n",
      "0s - loss: 0.0274 - acc: 0.9250 - val_loss: 0.0525 - val_acc: 0.6567\n",
      "Epoch 58/500\n",
      "0s - loss: 0.0289 - acc: 0.9227 - val_loss: 0.0486 - val_acc: 0.6456\n",
      "Epoch 59/500\n",
      "0s - loss: 0.0262 - acc: 0.9201 - val_loss: 0.0476 - val_acc: 0.6547\n",
      "Epoch 60/500\n",
      "Epoch 00059: val_loss improved from 0.05068 to 0.04779, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0256 - acc: 0.9221 - val_loss: 0.0478 - val_acc: 0.6496\n",
      "Epoch 61/500\n",
      "0s - loss: 0.0254 - acc: 0.9283 - val_loss: 0.0467 - val_acc: 0.6346\n",
      "Epoch 62/500\n",
      "0s - loss: 0.0258 - acc: 0.9260 - val_loss: 0.0491 - val_acc: 0.6456\n",
      "Epoch 63/500\n",
      "0s - loss: 0.0258 - acc: 0.9240 - val_loss: 0.0468 - val_acc: 0.6426\n",
      "Epoch 64/500\n",
      "0s - loss: 0.0258 - acc: 0.9208 - val_loss: 0.0483 - val_acc: 0.6476\n",
      "Epoch 65/500\n",
      "0s - loss: 0.0262 - acc: 0.9264 - val_loss: 0.0489 - val_acc: 0.6476\n",
      "Epoch 66/500\n",
      "0s - loss: 0.0250 - acc: 0.9251 - val_loss: 0.0541 - val_acc: 0.6527\n",
      "Epoch 67/500\n",
      "0s - loss: 0.0252 - acc: 0.9236 - val_loss: 0.0580 - val_acc: 0.6607\n",
      "Epoch 68/500\n",
      "0s - loss: 0.0236 - acc: 0.9259 - val_loss: 0.0528 - val_acc: 0.6517\n",
      "Epoch 69/500\n",
      "0s - loss: 0.0234 - acc: 0.9295 - val_loss: 0.0482 - val_acc: 0.6486\n",
      "Epoch 70/500\n",
      "Epoch 00069: val_loss improved from 0.04779 to 0.04683, saving model to ./tmp/weights.best.cntk.hdf5\n",
      "0s - loss: 0.0243 - acc: 0.9244 - val_loss: 0.0468 - val_acc: 0.6426\n",
      "Epoch 71/500\n",
      "0s - loss: 0.0232 - acc: 0.9337 - val_loss: 0.0530 - val_acc: 0.6446\n",
      "Epoch 72/500\n",
      "0s - loss: 0.0248 - acc: 0.9292 - val_loss: 0.0584 - val_acc: 0.6376\n",
      "Epoch 73/500\n",
      "0s - loss: 0.0221 - acc: 0.9232 - val_loss: 0.0551 - val_acc: 0.6286\n",
      "Epoch 74/500\n",
      "0s - loss: 0.0224 - acc: 0.9258 - val_loss: 0.0532 - val_acc: 0.6396\n",
      "Epoch 75/500\n",
      "0s - loss: 0.0199 - acc: 0.9273 - val_loss: 0.0535 - val_acc: 0.6306\n",
      "Epoch 76/500\n",
      "0s - loss: 0.0224 - acc: 0.9295 - val_loss: 0.0577 - val_acc: 0.6386\n",
      "Epoch 77/500\n",
      "0s - loss: 0.0216 - acc: 0.9295 - val_loss: 0.0603 - val_acc: 0.6406\n",
      "Epoch 78/500\n",
      "0s - loss: 0.0207 - acc: 0.9242 - val_loss: 0.0527 - val_acc: 0.6496\n",
      "Epoch 79/500\n",
      "0s - loss: 0.0218 - acc: 0.9298 - val_loss: 0.0493 - val_acc: 0.6336\n",
      "Epoch 80/500\n",
      "Epoch 00079: val_loss did not improve\n",
      "0s - loss: 0.0206 - acc: 0.9302 - val_loss: 0.0523 - val_acc: 0.6346\n",
      "Epoch 81/500\n",
      "0s - loss: 0.0198 - acc: 0.9226 - val_loss: 0.0579 - val_acc: 0.6456\n",
      "Epoch 82/500\n",
      "0s - loss: 0.0201 - acc: 0.9307 - val_loss: 0.0511 - val_acc: 0.6446\n",
      "Epoch 83/500\n",
      "0s - loss: 0.0206 - acc: 0.9231 - val_loss: 0.0497 - val_acc: 0.6466\n",
      "Epoch 84/500\n",
      "0s - loss: 0.0199 - acc: 0.9272 - val_loss: 0.0557 - val_acc: 0.6336\n",
      "Epoch 85/500\n",
      "0s - loss: 0.0193 - acc: 0.9278 - val_loss: 0.0571 - val_acc: 0.6396\n",
      "Epoch 86/500\n",
      "0s - loss: 0.0212 - acc: 0.9332 - val_loss: 0.0516 - val_acc: 0.6396\n",
      "Epoch 87/500\n",
      "0s - loss: 0.0178 - acc: 0.9275 - val_loss: 0.0515 - val_acc: 0.6607\n",
      "Epoch 88/500\n",
      "0s - loss: 0.0186 - acc: 0.9323 - val_loss: 0.0511 - val_acc: 0.6537\n",
      "Epoch 89/500\n",
      "0s - loss: 0.0191 - acc: 0.9253 - val_loss: 0.0543 - val_acc: 0.6607\n",
      "Epoch 90/500\n",
      "Epoch 00089: val_loss did not improve\n",
      "0s - loss: 0.0188 - acc: 0.9263 - val_loss: 0.0517 - val_acc: 0.6426\n",
      "Epoch 91/500\n",
      "0s - loss: 0.0176 - acc: 0.9238 - val_loss: 0.0517 - val_acc: 0.6597\n",
      "Epoch 92/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0174 - acc: 0.9337 - val_loss: 0.0501 - val_acc: 0.6587\n",
      "Epoch 93/500\n",
      "0s - loss: 0.0169 - acc: 0.9309 - val_loss: 0.0475 - val_acc: 0.6557\n",
      "Epoch 94/500\n",
      "0s - loss: 0.0161 - acc: 0.9301 - val_loss: 0.0452 - val_acc: 0.6486\n",
      "Epoch 95/500\n",
      "0s - loss: 0.0174 - acc: 0.9289 - val_loss: 0.0543 - val_acc: 0.6557\n",
      "Epoch 96/500\n",
      "0s - loss: 0.0177 - acc: 0.9283 - val_loss: 0.0542 - val_acc: 0.6597\n",
      "Epoch 97/500\n",
      "0s - loss: 0.0172 - acc: 0.9330 - val_loss: 0.0538 - val_acc: 0.6587\n",
      "Epoch 98/500\n",
      "0s - loss: 0.0162 - acc: 0.9369 - val_loss: 0.0540 - val_acc: 0.6577\n",
      "Epoch 99/500\n",
      "0s - loss: 0.0165 - acc: 0.9351 - val_loss: 0.0492 - val_acc: 0.6527\n",
      "Epoch 100/500\n",
      "Epoch 00099: val_loss did not improve\n",
      "0s - loss: 0.0161 - acc: 0.9331 - val_loss: 0.0503 - val_acc: 0.6647\n",
      "Epoch 101/500\n",
      "0s - loss: 0.0173 - acc: 0.9261 - val_loss: 0.0445 - val_acc: 0.6557\n",
      "Epoch 102/500\n",
      "0s - loss: 0.0161 - acc: 0.9281 - val_loss: 0.0445 - val_acc: 0.6627\n",
      "Epoch 103/500\n",
      "0s - loss: 0.0160 - acc: 0.9345 - val_loss: 0.0458 - val_acc: 0.6607\n",
      "Epoch 104/500\n",
      "0s - loss: 0.0156 - acc: 0.9319 - val_loss: 0.0423 - val_acc: 0.6637\n",
      "Epoch 105/500\n",
      "0s - loss: 0.0160 - acc: 0.9303 - val_loss: 0.0459 - val_acc: 0.6597\n",
      "Epoch 106/500\n",
      "0s - loss: 0.0155 - acc: 0.9301 - val_loss: 0.0473 - val_acc: 0.6597\n",
      "Epoch 107/500\n",
      "0s - loss: 0.0158 - acc: 0.9256 - val_loss: 0.0557 - val_acc: 0.6466\n",
      "Epoch 108/500\n",
      "0s - loss: 0.0166 - acc: 0.9337 - val_loss: 0.0523 - val_acc: 0.6517\n",
      "Epoch 109/500\n",
      "0s - loss: 0.0143 - acc: 0.9302 - val_loss: 0.0553 - val_acc: 0.6577\n",
      "Epoch 110/500\n",
      "Epoch 00109: val_loss did not improve\n",
      "0s - loss: 0.0151 - acc: 0.9323 - val_loss: 0.0527 - val_acc: 0.6527\n",
      "Epoch 111/500\n",
      "0s - loss: 0.0144 - acc: 0.9295 - val_loss: 0.0546 - val_acc: 0.6647\n",
      "Epoch 112/500\n",
      "0s - loss: 0.0154 - acc: 0.9343 - val_loss: 0.0580 - val_acc: 0.6517\n",
      "Epoch 113/500\n",
      "0s - loss: 0.0156 - acc: 0.9320 - val_loss: 0.0536 - val_acc: 0.6607\n",
      "Epoch 114/500\n",
      "0s - loss: 0.0147 - acc: 0.9319 - val_loss: 0.0545 - val_acc: 0.6607\n",
      "Epoch 115/500\n",
      "0s - loss: 0.0154 - acc: 0.9365 - val_loss: 0.0556 - val_acc: 0.6587\n",
      "Epoch 116/500\n",
      "0s - loss: 0.0144 - acc: 0.9354 - val_loss: 0.0558 - val_acc: 0.6627\n",
      "Epoch 117/500\n",
      "0s - loss: 0.0137 - acc: 0.9339 - val_loss: 0.0571 - val_acc: 0.6597\n",
      "Epoch 118/500\n",
      "0s - loss: 0.0149 - acc: 0.9331 - val_loss: 0.0643 - val_acc: 0.6547\n",
      "Epoch 119/500\n",
      "0s - loss: 0.0154 - acc: 0.9342 - val_loss: 0.0617 - val_acc: 0.6597\n",
      "Epoch 120/500\n",
      "Epoch 00119: val_loss did not improve\n",
      "0s - loss: 0.0139 - acc: 0.9348 - val_loss: 0.0633 - val_acc: 0.6496\n",
      "Epoch 121/500\n",
      "0s - loss: 0.0160 - acc: 0.9327 - val_loss: 0.0612 - val_acc: 0.6577\n",
      "Epoch 122/500\n",
      "0s - loss: 0.0144 - acc: 0.9336 - val_loss: 0.0587 - val_acc: 0.6617\n",
      "Epoch 123/500\n",
      "0s - loss: 0.0149 - acc: 0.9288 - val_loss: 0.0555 - val_acc: 0.6597\n",
      "Epoch 124/500\n",
      "0s - loss: 0.0136 - acc: 0.9346 - val_loss: 0.0628 - val_acc: 0.6587\n",
      "Epoch 125/500\n",
      "0s - loss: 0.0127 - acc: 0.9303 - val_loss: 0.0633 - val_acc: 0.6597\n",
      "Epoch 126/500\n",
      "0s - loss: 0.0130 - acc: 0.9386 - val_loss: 0.0655 - val_acc: 0.6567\n",
      "Epoch 127/500\n",
      "0s - loss: 0.0143 - acc: 0.9307 - val_loss: 0.0644 - val_acc: 0.6426\n",
      "Epoch 128/500\n",
      "0s - loss: 0.0130 - acc: 0.9333 - val_loss: 0.0619 - val_acc: 0.6446\n",
      "Epoch 129/500\n",
      "0s - loss: 0.0132 - acc: 0.9371 - val_loss: 0.0625 - val_acc: 0.6446\n",
      "Epoch 130/500\n",
      "Epoch 00129: val_loss did not improve\n",
      "0s - loss: 0.0150 - acc: 0.9298 - val_loss: 0.0641 - val_acc: 0.6537\n",
      "Epoch 131/500\n",
      "0s - loss: 0.0136 - acc: 0.9358 - val_loss: 0.0621 - val_acc: 0.6617\n",
      "Epoch 132/500\n",
      "0s - loss: 0.0128 - acc: 0.9366 - val_loss: 0.0612 - val_acc: 0.6587\n",
      "Epoch 133/500\n",
      "0s - loss: 0.0135 - acc: 0.9328 - val_loss: 0.0634 - val_acc: 0.6486\n",
      "Epoch 134/500\n",
      "0s - loss: 0.0121 - acc: 0.9327 - val_loss: 0.0613 - val_acc: 0.6537\n",
      "Epoch 135/500\n",
      "0s - loss: 0.0128 - acc: 0.9298 - val_loss: 0.0582 - val_acc: 0.6577\n",
      "Epoch 136/500\n",
      "0s - loss: 0.0130 - acc: 0.9349 - val_loss: 0.0649 - val_acc: 0.6587\n",
      "Epoch 137/500\n",
      "0s - loss: 0.0129 - acc: 0.9330 - val_loss: 0.0713 - val_acc: 0.6567\n",
      "Epoch 138/500\n",
      "0s - loss: 0.0115 - acc: 0.9339 - val_loss: 0.0690 - val_acc: 0.6577\n",
      "Epoch 139/500\n",
      "0s - loss: 0.0124 - acc: 0.9328 - val_loss: 0.0656 - val_acc: 0.6587\n",
      "Epoch 140/500\n",
      "Epoch 00139: val_loss did not improve\n",
      "0s - loss: 0.0123 - acc: 0.9381 - val_loss: 0.0642 - val_acc: 0.6577\n",
      "Epoch 141/500\n",
      "0s - loss: 0.0115 - acc: 0.9359 - val_loss: 0.0643 - val_acc: 0.6507\n",
      "Epoch 142/500\n",
      "0s - loss: 0.0123 - acc: 0.9346 - val_loss: 0.0619 - val_acc: 0.6577\n",
      "Epoch 143/500\n",
      "0s - loss: 0.0113 - acc: 0.9388 - val_loss: 0.0750 - val_acc: 0.6617\n",
      "Epoch 144/500\n",
      "0s - loss: 0.0146 - acc: 0.9340 - val_loss: 0.0729 - val_acc: 0.6496\n",
      "Epoch 145/500\n",
      "0s - loss: 0.0124 - acc: 0.9419 - val_loss: 0.0671 - val_acc: 0.6617\n",
      "Epoch 146/500\n",
      "0s - loss: 0.0131 - acc: 0.9392 - val_loss: 0.0680 - val_acc: 0.6607\n",
      "Epoch 147/500\n",
      "0s - loss: 0.0122 - acc: 0.9354 - val_loss: 0.0674 - val_acc: 0.6647\n",
      "Epoch 148/500\n",
      "0s - loss: 0.0124 - acc: 0.9352 - val_loss: 0.0736 - val_acc: 0.6617\n",
      "Epoch 149/500\n",
      "0s - loss: 0.0120 - acc: 0.9296 - val_loss: 0.0681 - val_acc: 0.6507\n",
      "Epoch 150/500\n",
      "Epoch 00149: val_loss did not improve\n",
      "0s - loss: 0.0116 - acc: 0.9374 - val_loss: 0.0782 - val_acc: 0.6567\n",
      "Epoch 151/500\n",
      "0s - loss: 0.0120 - acc: 0.9362 - val_loss: 0.0798 - val_acc: 0.6537\n",
      "Epoch 152/500\n",
      "0s - loss: 0.0116 - acc: 0.9333 - val_loss: 0.0775 - val_acc: 0.6617\n",
      "Epoch 153/500\n",
      "0s - loss: 0.0118 - acc: 0.9374 - val_loss: 0.0778 - val_acc: 0.6617\n",
      "Epoch 154/500\n",
      "0s - loss: 0.0120 - acc: 0.9351 - val_loss: 0.0735 - val_acc: 0.6537\n",
      "Epoch 155/500\n",
      "0s - loss: 0.0120 - acc: 0.9359 - val_loss: 0.0745 - val_acc: 0.6527\n",
      "Epoch 156/500\n",
      "0s - loss: 0.0119 - acc: 0.9350 - val_loss: 0.0745 - val_acc: 0.6647\n",
      "Epoch 157/500\n",
      "0s - loss: 0.0114 - acc: 0.9311 - val_loss: 0.0752 - val_acc: 0.6607\n",
      "Epoch 158/500\n",
      "0s - loss: 0.0114 - acc: 0.9370 - val_loss: 0.0812 - val_acc: 0.6627\n",
      "Epoch 159/500\n",
      "0s - loss: 0.0119 - acc: 0.9350 - val_loss: 0.0754 - val_acc: 0.6627\n",
      "Epoch 160/500\n",
      "Epoch 00159: val_loss did not improve\n",
      "0s - loss: 0.0119 - acc: 0.9360 - val_loss: 0.0747 - val_acc: 0.6537\n",
      "Epoch 161/500\n",
      "0s - loss: 0.0112 - acc: 0.9338 - val_loss: 0.0726 - val_acc: 0.6617\n",
      "Epoch 162/500\n",
      "0s - loss: 0.0115 - acc: 0.9428 - val_loss: 0.0771 - val_acc: 0.6547\n",
      "Epoch 163/500\n",
      "0s - loss: 0.0104 - acc: 0.9360 - val_loss: 0.0795 - val_acc: 0.6537\n",
      "Epoch 164/500\n",
      "0s - loss: 0.0105 - acc: 0.9329 - val_loss: 0.0787 - val_acc: 0.6607\n",
      "Epoch 165/500\n",
      "0s - loss: 0.0111 - acc: 0.9376 - val_loss: 0.0738 - val_acc: 0.6496\n",
      "Epoch 166/500\n",
      "0s - loss: 0.0114 - acc: 0.9374 - val_loss: 0.0712 - val_acc: 0.6537\n",
      "Epoch 167/500\n",
      "0s - loss: 0.0102 - acc: 0.9377 - val_loss: 0.0783 - val_acc: 0.6507\n",
      "Epoch 168/500\n",
      "0s - loss: 0.0103 - acc: 0.9355 - val_loss: 0.0789 - val_acc: 0.6517\n",
      "Epoch 169/500\n",
      "0s - loss: 0.0095 - acc: 0.9351 - val_loss: 0.0737 - val_acc: 0.6527\n",
      "Epoch 170/500\n",
      "Epoch 00169: val_loss did not improve\n",
      "0s - loss: 0.0101 - acc: 0.9381 - val_loss: 0.0730 - val_acc: 0.6507\n",
      "Epoch 171/500\n",
      "0s - loss: 0.0116 - acc: 0.9308 - val_loss: 0.0738 - val_acc: 0.6426\n",
      "Epoch 172/500\n",
      "0s - loss: 0.0103 - acc: 0.9308 - val_loss: 0.0721 - val_acc: 0.6466\n",
      "Epoch 173/500\n",
      "0s - loss: 0.0112 - acc: 0.9320 - val_loss: 0.0778 - val_acc: 0.6386\n",
      "Epoch 174/500\n",
      "0s - loss: 0.0121 - acc: 0.9411 - val_loss: 0.0828 - val_acc: 0.6607\n",
      "Epoch 175/500\n",
      "0s - loss: 0.0106 - acc: 0.9345 - val_loss: 0.0843 - val_acc: 0.6577\n",
      "Epoch 176/500\n",
      "0s - loss: 0.0101 - acc: 0.9382 - val_loss: 0.0837 - val_acc: 0.6577\n",
      "Epoch 177/500\n",
      "0s - loss: 0.0100 - acc: 0.9409 - val_loss: 0.0873 - val_acc: 0.6466\n",
      "Epoch 178/500\n",
      "0s - loss: 0.0098 - acc: 0.9342 - val_loss: 0.0850 - val_acc: 0.6607\n",
      "Epoch 179/500\n",
      "0s - loss: 0.0103 - acc: 0.9371 - val_loss: 0.0816 - val_acc: 0.6657\n",
      "Epoch 180/500\n",
      "Epoch 00179: val_loss did not improve\n",
      "0s - loss: 0.0089 - acc: 0.9362 - val_loss: 0.0789 - val_acc: 0.6557\n",
      "Epoch 181/500\n",
      "0s - loss: 0.0103 - acc: 0.9352 - val_loss: 0.0924 - val_acc: 0.6627\n",
      "Epoch 182/500\n",
      "0s - loss: 0.0107 - acc: 0.9379 - val_loss: 0.0981 - val_acc: 0.6567\n",
      "Epoch 183/500\n",
      "0s - loss: 0.0106 - acc: 0.9367 - val_loss: 0.0916 - val_acc: 0.6557\n",
      "Epoch 184/500\n",
      "0s - loss: 0.0104 - acc: 0.9354 - val_loss: 0.0920 - val_acc: 0.6627\n",
      "Epoch 185/500\n",
      "0s - loss: 0.0102 - acc: 0.9412 - val_loss: 0.0884 - val_acc: 0.6567\n",
      "Epoch 186/500\n",
      "0s - loss: 0.0100 - acc: 0.9329 - val_loss: 0.0794 - val_acc: 0.6627\n",
      "Epoch 187/500\n",
      "0s - loss: 0.0094 - acc: 0.9384 - val_loss: 0.0778 - val_acc: 0.6607\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0094 - acc: 0.9430 - val_loss: 0.0869 - val_acc: 0.6587\n",
      "Epoch 189/500\n",
      "0s - loss: 0.0094 - acc: 0.9396 - val_loss: 0.0854 - val_acc: 0.6406\n",
      "Epoch 190/500\n",
      "Epoch 00189: val_loss did not improve\n",
      "0s - loss: 0.0099 - acc: 0.9399 - val_loss: 0.0802 - val_acc: 0.6587\n",
      "Epoch 191/500\n",
      "0s - loss: 0.0102 - acc: 0.9355 - val_loss: 0.0815 - val_acc: 0.6567\n",
      "Epoch 192/500\n",
      "0s - loss: 0.0092 - acc: 0.9359 - val_loss: 0.0794 - val_acc: 0.6537\n",
      "Epoch 193/500\n",
      "0s - loss: 0.0092 - acc: 0.9408 - val_loss: 0.0824 - val_acc: 0.6567\n",
      "Epoch 194/500\n",
      "0s - loss: 0.0097 - acc: 0.9381 - val_loss: 0.0848 - val_acc: 0.6587\n",
      "Epoch 195/500\n",
      "0s - loss: 0.0105 - acc: 0.9370 - val_loss: 0.0837 - val_acc: 0.6637\n",
      "Epoch 196/500\n",
      "0s - loss: 0.0096 - acc: 0.9379 - val_loss: 0.0856 - val_acc: 0.6657\n",
      "Epoch 197/500\n",
      "0s - loss: 0.0083 - acc: 0.9430 - val_loss: 0.0833 - val_acc: 0.6587\n",
      "Epoch 198/500\n",
      "0s - loss: 0.0097 - acc: 0.9349 - val_loss: 0.0897 - val_acc: 0.6547\n",
      "Epoch 199/500\n",
      "0s - loss: 0.0095 - acc: 0.9381 - val_loss: 0.0939 - val_acc: 0.6537\n",
      "Epoch 200/500\n",
      "Epoch 00199: val_loss did not improve\n",
      "0s - loss: 0.0097 - acc: 0.9392 - val_loss: 0.0964 - val_acc: 0.6557\n",
      "Epoch 201/500\n",
      "0s - loss: 0.0101 - acc: 0.9322 - val_loss: 0.0955 - val_acc: 0.6476\n",
      "Epoch 202/500\n",
      "0s - loss: 0.0093 - acc: 0.9354 - val_loss: 0.0923 - val_acc: 0.6567\n",
      "Epoch 203/500\n",
      "0s - loss: 0.0103 - acc: 0.9401 - val_loss: 0.0910 - val_acc: 0.6637\n",
      "Epoch 204/500\n",
      "0s - loss: 0.0092 - acc: 0.9360 - val_loss: 0.0896 - val_acc: 0.6597\n",
      "Epoch 205/500\n",
      "0s - loss: 0.0092 - acc: 0.9404 - val_loss: 0.0911 - val_acc: 0.6607\n",
      "Epoch 206/500\n",
      "0s - loss: 0.0090 - acc: 0.9379 - val_loss: 0.0975 - val_acc: 0.6617\n",
      "Epoch 207/500\n",
      "0s - loss: 0.0091 - acc: 0.9430 - val_loss: 0.0956 - val_acc: 0.6557\n",
      "Epoch 208/500\n",
      "0s - loss: 0.0085 - acc: 0.9444 - val_loss: 0.0912 - val_acc: 0.6647\n",
      "Epoch 209/500\n",
      "0s - loss: 0.0102 - acc: 0.9374 - val_loss: 0.0927 - val_acc: 0.6537\n",
      "Epoch 210/500\n",
      "Epoch 00209: val_loss did not improve\n",
      "0s - loss: 0.0100 - acc: 0.9370 - val_loss: 0.0916 - val_acc: 0.6587\n",
      "Epoch 211/500\n",
      "0s - loss: 0.0090 - acc: 0.9356 - val_loss: 0.0925 - val_acc: 0.6567\n",
      "Epoch 212/500\n",
      "0s - loss: 0.0100 - acc: 0.9369 - val_loss: 0.0910 - val_acc: 0.6577\n",
      "Epoch 213/500\n",
      "0s - loss: 0.0108 - acc: 0.9397 - val_loss: 0.0879 - val_acc: 0.6607\n",
      "Epoch 214/500\n",
      "0s - loss: 0.0098 - acc: 0.9366 - val_loss: 0.0874 - val_acc: 0.6567\n",
      "Epoch 215/500\n",
      "0s - loss: 0.0093 - acc: 0.9408 - val_loss: 0.0866 - val_acc: 0.6577\n",
      "Epoch 216/500\n",
      "0s - loss: 0.0092 - acc: 0.9433 - val_loss: 0.0907 - val_acc: 0.6587\n",
      "Epoch 217/500\n",
      "0s - loss: 0.0099 - acc: 0.9387 - val_loss: 0.0931 - val_acc: 0.6446\n",
      "Epoch 218/500\n",
      "0s - loss: 0.0081 - acc: 0.9354 - val_loss: 0.0882 - val_acc: 0.6577\n",
      "Epoch 219/500\n",
      "0s - loss: 0.0101 - acc: 0.9445 - val_loss: 0.0953 - val_acc: 0.6527\n",
      "Epoch 220/500\n",
      "Epoch 00219: val_loss did not improve\n",
      "0s - loss: 0.0100 - acc: 0.9394 - val_loss: 0.0951 - val_acc: 0.6647\n",
      "Epoch 221/500\n",
      "0s - loss: 0.0098 - acc: 0.9380 - val_loss: 0.1015 - val_acc: 0.6517\n",
      "Epoch 222/500\n",
      "0s - loss: 0.0100 - acc: 0.9354 - val_loss: 0.1058 - val_acc: 0.6597\n",
      "Epoch 223/500\n",
      "0s - loss: 0.0096 - acc: 0.9364 - val_loss: 0.1068 - val_acc: 0.6567\n",
      "Epoch 224/500\n",
      "0s - loss: 0.0102 - acc: 0.9377 - val_loss: 0.0961 - val_acc: 0.6657\n",
      "Epoch 225/500\n",
      "0s - loss: 0.0086 - acc: 0.9338 - val_loss: 0.0925 - val_acc: 0.6476\n",
      "Epoch 226/500\n",
      "0s - loss: 0.0093 - acc: 0.9377 - val_loss: 0.0941 - val_acc: 0.6697\n",
      "Epoch 227/500\n",
      "0s - loss: 0.0098 - acc: 0.9370 - val_loss: 0.0938 - val_acc: 0.6567\n",
      "Epoch 228/500\n",
      "0s - loss: 0.0105 - acc: 0.9428 - val_loss: 0.1013 - val_acc: 0.6707\n",
      "Epoch 229/500\n",
      "0s - loss: 0.0089 - acc: 0.9397 - val_loss: 0.1079 - val_acc: 0.6657\n",
      "Epoch 230/500\n",
      "Epoch 00229: val_loss did not improve\n",
      "0s - loss: 0.0089 - acc: 0.9430 - val_loss: 0.1053 - val_acc: 0.6657\n",
      "Epoch 231/500\n",
      "0s - loss: 0.0088 - acc: 0.9398 - val_loss: 0.0990 - val_acc: 0.6627\n",
      "Epoch 232/500\n",
      "0s - loss: 0.0082 - acc: 0.9348 - val_loss: 0.0907 - val_acc: 0.6617\n",
      "Epoch 233/500\n",
      "0s - loss: 0.0087 - acc: 0.9360 - val_loss: 0.0900 - val_acc: 0.6657\n",
      "Epoch 234/500\n",
      "0s - loss: 0.0090 - acc: 0.9431 - val_loss: 0.0886 - val_acc: 0.6717\n",
      "Epoch 235/500\n",
      "0s - loss: 0.0083 - acc: 0.9425 - val_loss: 0.0899 - val_acc: 0.6667\n",
      "Epoch 236/500\n",
      "0s - loss: 0.0086 - acc: 0.9409 - val_loss: 0.0863 - val_acc: 0.6737\n",
      "Epoch 237/500\n",
      "0s - loss: 0.0089 - acc: 0.9430 - val_loss: 0.0930 - val_acc: 0.6787\n",
      "Epoch 238/500\n",
      "0s - loss: 0.0094 - acc: 0.9407 - val_loss: 0.0926 - val_acc: 0.6667\n",
      "Epoch 239/500\n",
      "0s - loss: 0.0085 - acc: 0.9359 - val_loss: 0.0974 - val_acc: 0.6737\n",
      "Epoch 240/500\n",
      "Epoch 00239: val_loss did not improve\n",
      "0s - loss: 0.0088 - acc: 0.9419 - val_loss: 0.0982 - val_acc: 0.6657\n",
      "Epoch 241/500\n",
      "0s - loss: 0.0097 - acc: 0.9411 - val_loss: 0.0950 - val_acc: 0.6777\n",
      "Epoch 242/500\n",
      "0s - loss: 0.0089 - acc: 0.9387 - val_loss: 0.1003 - val_acc: 0.6657\n",
      "Epoch 243/500\n",
      "0s - loss: 0.0087 - acc: 0.9384 - val_loss: 0.1008 - val_acc: 0.6647\n",
      "Epoch 244/500\n",
      "0s - loss: 0.0083 - acc: 0.9422 - val_loss: 0.0976 - val_acc: 0.6747\n",
      "Epoch 245/500\n",
      "0s - loss: 0.0083 - acc: 0.9368 - val_loss: 0.0982 - val_acc: 0.6687\n",
      "Epoch 246/500\n",
      "0s - loss: 0.0086 - acc: 0.9381 - val_loss: 0.0984 - val_acc: 0.6757\n",
      "Epoch 247/500\n",
      "0s - loss: 0.0073 - acc: 0.9439 - val_loss: 0.0980 - val_acc: 0.6657\n",
      "Epoch 248/500\n",
      "0s - loss: 0.0081 - acc: 0.9364 - val_loss: 0.0972 - val_acc: 0.6737\n",
      "Epoch 249/500\n",
      "0s - loss: 0.0085 - acc: 0.9370 - val_loss: 0.0966 - val_acc: 0.6657\n",
      "Epoch 250/500\n",
      "Epoch 00249: val_loss did not improve\n",
      "0s - loss: 0.0088 - acc: 0.9409 - val_loss: 0.0935 - val_acc: 0.6737\n",
      "Epoch 251/500\n",
      "0s - loss: 0.0087 - acc: 0.9362 - val_loss: 0.1012 - val_acc: 0.6687\n",
      "Epoch 252/500\n",
      "0s - loss: 0.0074 - acc: 0.9429 - val_loss: 0.1096 - val_acc: 0.6667\n",
      "Epoch 253/500\n",
      "0s - loss: 0.0080 - acc: 0.9362 - val_loss: 0.1015 - val_acc: 0.6777\n",
      "Epoch 254/500\n",
      "0s - loss: 0.0083 - acc: 0.9398 - val_loss: 0.0953 - val_acc: 0.6717\n",
      "Epoch 255/500\n",
      "0s - loss: 0.0088 - acc: 0.9364 - val_loss: 0.0976 - val_acc: 0.6667\n",
      "Epoch 256/500\n",
      "0s - loss: 0.0090 - acc: 0.9420 - val_loss: 0.0955 - val_acc: 0.6707\n",
      "Epoch 257/500\n",
      "0s - loss: 0.0080 - acc: 0.9359 - val_loss: 0.1065 - val_acc: 0.6627\n",
      "Epoch 258/500\n",
      "0s - loss: 0.0081 - acc: 0.9429 - val_loss: 0.1116 - val_acc: 0.6747\n",
      "Epoch 259/500\n",
      "0s - loss: 0.0078 - acc: 0.9427 - val_loss: 0.1084 - val_acc: 0.6657\n",
      "Epoch 260/500\n",
      "Epoch 00259: val_loss did not improve\n",
      "0s - loss: 0.0078 - acc: 0.9435 - val_loss: 0.1061 - val_acc: 0.6737\n",
      "Epoch 261/500\n",
      "0s - loss: 0.0076 - acc: 0.9438 - val_loss: 0.1058 - val_acc: 0.6667\n",
      "Epoch 262/500\n",
      "0s - loss: 0.0082 - acc: 0.9406 - val_loss: 0.1024 - val_acc: 0.6727\n",
      "Epoch 263/500\n",
      "0s - loss: 0.0086 - acc: 0.9456 - val_loss: 0.1053 - val_acc: 0.6677\n",
      "Epoch 264/500\n",
      "0s - loss: 0.0089 - acc: 0.9419 - val_loss: 0.1022 - val_acc: 0.6757\n",
      "Epoch 265/500\n",
      "0s - loss: 0.0084 - acc: 0.9391 - val_loss: 0.1004 - val_acc: 0.6777\n",
      "Epoch 266/500\n",
      "0s - loss: 0.0080 - acc: 0.9398 - val_loss: 0.1001 - val_acc: 0.6777\n",
      "Epoch 267/500\n",
      "0s - loss: 0.0076 - acc: 0.9431 - val_loss: 0.1001 - val_acc: 0.6777\n",
      "Epoch 268/500\n",
      "0s - loss: 0.0072 - acc: 0.9443 - val_loss: 0.0966 - val_acc: 0.6777\n",
      "Epoch 269/500\n",
      "0s - loss: 0.0079 - acc: 0.9416 - val_loss: 0.1081 - val_acc: 0.6717\n",
      "Epoch 270/500\n",
      "Epoch 00269: val_loss did not improve\n",
      "0s - loss: 0.0085 - acc: 0.9378 - val_loss: 0.1098 - val_acc: 0.6757\n",
      "Epoch 271/500\n",
      "0s - loss: 0.0083 - acc: 0.9454 - val_loss: 0.1118 - val_acc: 0.6797\n",
      "Epoch 272/500\n",
      "0s - loss: 0.0083 - acc: 0.9404 - val_loss: 0.1132 - val_acc: 0.6767\n",
      "Epoch 273/500\n",
      "0s - loss: 0.0086 - acc: 0.9407 - val_loss: 0.1070 - val_acc: 0.6807\n",
      "Epoch 274/500\n",
      "0s - loss: 0.0078 - acc: 0.9415 - val_loss: 0.1043 - val_acc: 0.6807\n",
      "Epoch 275/500\n",
      "0s - loss: 0.0080 - acc: 0.9459 - val_loss: 0.1095 - val_acc: 0.6817\n",
      "Epoch 276/500\n",
      "0s - loss: 0.0080 - acc: 0.9371 - val_loss: 0.1054 - val_acc: 0.6657\n",
      "Epoch 277/500\n",
      "0s - loss: 0.0076 - acc: 0.9427 - val_loss: 0.1078 - val_acc: 0.6797\n",
      "Epoch 278/500\n",
      "0s - loss: 0.0074 - acc: 0.9431 - val_loss: 0.1083 - val_acc: 0.6747\n",
      "Epoch 279/500\n",
      "0s - loss: 0.0077 - acc: 0.9449 - val_loss: 0.1129 - val_acc: 0.6797\n",
      "Epoch 280/500\n",
      "Epoch 00279: val_loss did not improve\n",
      "0s - loss: 0.0072 - acc: 0.9430 - val_loss: 0.1059 - val_acc: 0.6757\n",
      "Epoch 281/500\n",
      "0s - loss: 0.0077 - acc: 0.9402 - val_loss: 0.1079 - val_acc: 0.6747\n",
      "Epoch 282/500\n",
      "0s - loss: 0.0077 - acc: 0.9460 - val_loss: 0.1068 - val_acc: 0.6787\n",
      "Epoch 283/500\n",
      "0s - loss: 0.0075 - acc: 0.9402 - val_loss: 0.1037 - val_acc: 0.6797\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0074 - acc: 0.9464 - val_loss: 0.1023 - val_acc: 0.6877\n",
      "Epoch 285/500\n",
      "0s - loss: 0.0079 - acc: 0.9425 - val_loss: 0.0976 - val_acc: 0.6857\n",
      "Epoch 286/500\n",
      "0s - loss: 0.0087 - acc: 0.9382 - val_loss: 0.1035 - val_acc: 0.6777\n",
      "Epoch 287/500\n",
      "0s - loss: 0.0079 - acc: 0.9433 - val_loss: 0.1001 - val_acc: 0.6727\n",
      "Epoch 288/500\n",
      "0s - loss: 0.0079 - acc: 0.9369 - val_loss: 0.1017 - val_acc: 0.6847\n",
      "Epoch 289/500\n",
      "0s - loss: 0.0072 - acc: 0.9466 - val_loss: 0.1021 - val_acc: 0.6747\n",
      "Epoch 290/500\n",
      "Epoch 00289: val_loss did not improve\n",
      "0s - loss: 0.0070 - acc: 0.9451 - val_loss: 0.1022 - val_acc: 0.6827\n",
      "Epoch 291/500\n",
      "0s - loss: 0.0068 - acc: 0.9445 - val_loss: 0.1094 - val_acc: 0.6787\n",
      "Epoch 292/500\n",
      "0s - loss: 0.0073 - acc: 0.9420 - val_loss: 0.0998 - val_acc: 0.6787\n",
      "Epoch 293/500\n",
      "0s - loss: 0.0075 - acc: 0.9420 - val_loss: 0.1063 - val_acc: 0.6817\n",
      "Epoch 294/500\n",
      "0s - loss: 0.0072 - acc: 0.9407 - val_loss: 0.1091 - val_acc: 0.6887\n",
      "Epoch 295/500\n",
      "0s - loss: 0.0086 - acc: 0.9437 - val_loss: 0.1146 - val_acc: 0.6857\n",
      "Epoch 296/500\n",
      "0s - loss: 0.0083 - acc: 0.9397 - val_loss: 0.1140 - val_acc: 0.6847\n",
      "Epoch 297/500\n",
      "0s - loss: 0.0076 - acc: 0.9409 - val_loss: 0.1104 - val_acc: 0.6857\n",
      "Epoch 298/500\n",
      "0s - loss: 0.0078 - acc: 0.9422 - val_loss: 0.1110 - val_acc: 0.6857\n",
      "Epoch 299/500\n",
      "0s - loss: 0.0089 - acc: 0.9418 - val_loss: 0.1107 - val_acc: 0.6857\n",
      "Epoch 300/500\n",
      "Epoch 00299: val_loss did not improve\n",
      "0s - loss: 0.0079 - acc: 0.9360 - val_loss: 0.1051 - val_acc: 0.6777\n",
      "Epoch 301/500\n",
      "0s - loss: 0.0081 - acc: 0.9449 - val_loss: 0.1010 - val_acc: 0.6877\n",
      "Epoch 302/500\n",
      "0s - loss: 0.0072 - acc: 0.9399 - val_loss: 0.1038 - val_acc: 0.6837\n",
      "Epoch 303/500\n",
      "0s - loss: 0.0080 - acc: 0.9415 - val_loss: 0.1023 - val_acc: 0.6907\n",
      "Epoch 304/500\n",
      "0s - loss: 0.0085 - acc: 0.9358 - val_loss: 0.1101 - val_acc: 0.6827\n",
      "Epoch 305/500\n",
      "0s - loss: 0.0075 - acc: 0.9446 - val_loss: 0.1076 - val_acc: 0.6867\n",
      "Epoch 306/500\n",
      "0s - loss: 0.0074 - acc: 0.9450 - val_loss: 0.1055 - val_acc: 0.6867\n",
      "Epoch 307/500\n",
      "0s - loss: 0.0076 - acc: 0.9411 - val_loss: 0.1128 - val_acc: 0.6887\n",
      "Epoch 308/500\n",
      "0s - loss: 0.0082 - acc: 0.9505 - val_loss: 0.1213 - val_acc: 0.6817\n",
      "Epoch 309/500\n",
      "0s - loss: 0.0074 - acc: 0.9422 - val_loss: 0.1226 - val_acc: 0.6707\n",
      "Epoch 310/500\n",
      "Epoch 00309: val_loss did not improve\n",
      "0s - loss: 0.0071 - acc: 0.9406 - val_loss: 0.1148 - val_acc: 0.6807\n",
      "Epoch 311/500\n",
      "0s - loss: 0.0077 - acc: 0.9450 - val_loss: 0.1193 - val_acc: 0.6847\n",
      "Epoch 312/500\n",
      "0s - loss: 0.0071 - acc: 0.9395 - val_loss: 0.1191 - val_acc: 0.6827\n",
      "Epoch 313/500\n",
      "0s - loss: 0.0068 - acc: 0.9420 - val_loss: 0.1180 - val_acc: 0.6827\n",
      "Epoch 314/500\n",
      "0s - loss: 0.0068 - acc: 0.9404 - val_loss: 0.1260 - val_acc: 0.6877\n",
      "Epoch 315/500\n",
      "0s - loss: 0.0076 - acc: 0.9416 - val_loss: 0.1237 - val_acc: 0.6767\n",
      "Epoch 316/500\n",
      "0s - loss: 0.0084 - acc: 0.9399 - val_loss: 0.1168 - val_acc: 0.6817\n",
      "Epoch 317/500\n",
      "0s - loss: 0.0074 - acc: 0.9468 - val_loss: 0.1153 - val_acc: 0.6737\n",
      "Epoch 318/500\n",
      "0s - loss: 0.0075 - acc: 0.9397 - val_loss: 0.1160 - val_acc: 0.6817\n",
      "Epoch 319/500\n",
      "0s - loss: 0.0072 - acc: 0.9422 - val_loss: 0.1210 - val_acc: 0.6847\n",
      "Epoch 320/500\n",
      "Epoch 00319: val_loss did not improve\n",
      "0s - loss: 0.0072 - acc: 0.9435 - val_loss: 0.1228 - val_acc: 0.6847\n",
      "Epoch 321/500\n",
      "0s - loss: 0.0067 - acc: 0.9443 - val_loss: 0.1221 - val_acc: 0.6837\n",
      "Epoch 322/500\n",
      "0s - loss: 0.0073 - acc: 0.9449 - val_loss: 0.1269 - val_acc: 0.6827\n",
      "Epoch 323/500\n",
      "0s - loss: 0.0070 - acc: 0.9450 - val_loss: 0.1204 - val_acc: 0.6817\n",
      "Epoch 324/500\n",
      "0s - loss: 0.0079 - acc: 0.9460 - val_loss: 0.1246 - val_acc: 0.6857\n",
      "Epoch 325/500\n",
      "0s - loss: 0.0067 - acc: 0.9450 - val_loss: 0.1249 - val_acc: 0.6937\n",
      "Epoch 326/500\n",
      "0s - loss: 0.0063 - acc: 0.9416 - val_loss: 0.1323 - val_acc: 0.6717\n",
      "Epoch 327/500\n",
      "0s - loss: 0.0072 - acc: 0.9376 - val_loss: 0.1323 - val_acc: 0.6947\n",
      "Epoch 328/500\n",
      "0s - loss: 0.0074 - acc: 0.9409 - val_loss: 0.1262 - val_acc: 0.6837\n",
      "Epoch 329/500\n",
      "0s - loss: 0.0073 - acc: 0.9398 - val_loss: 0.1189 - val_acc: 0.6767\n",
      "Epoch 330/500\n",
      "Epoch 00329: val_loss did not improve\n",
      "0s - loss: 0.0067 - acc: 0.9425 - val_loss: 0.1175 - val_acc: 0.6727\n",
      "Epoch 331/500\n",
      "0s - loss: 0.0066 - acc: 0.9440 - val_loss: 0.1228 - val_acc: 0.6657\n",
      "Epoch 332/500\n",
      "0s - loss: 0.0064 - acc: 0.9451 - val_loss: 0.1154 - val_acc: 0.6777\n",
      "Epoch 333/500\n",
      "0s - loss: 0.0072 - acc: 0.9446 - val_loss: 0.1138 - val_acc: 0.6807\n",
      "Epoch 334/500\n",
      "0s - loss: 0.0079 - acc: 0.9441 - val_loss: 0.1121 - val_acc: 0.6887\n",
      "Epoch 335/500\n",
      "0s - loss: 0.0072 - acc: 0.9446 - val_loss: 0.1122 - val_acc: 0.6847\n",
      "Epoch 336/500\n",
      "0s - loss: 0.0070 - acc: 0.9464 - val_loss: 0.1181 - val_acc: 0.6797\n",
      "Epoch 337/500\n",
      "0s - loss: 0.0077 - acc: 0.9474 - val_loss: 0.1125 - val_acc: 0.6777\n",
      "Epoch 338/500\n",
      "0s - loss: 0.0077 - acc: 0.9427 - val_loss: 0.1079 - val_acc: 0.6857\n",
      "Epoch 339/500\n",
      "0s - loss: 0.0082 - acc: 0.9440 - val_loss: 0.1128 - val_acc: 0.6847\n",
      "Epoch 340/500\n",
      "Epoch 00339: val_loss did not improve\n",
      "0s - loss: 0.0074 - acc: 0.9433 - val_loss: 0.1103 - val_acc: 0.6827\n",
      "Epoch 341/500\n",
      "0s - loss: 0.0070 - acc: 0.9453 - val_loss: 0.1106 - val_acc: 0.6747\n",
      "Epoch 342/500\n",
      "0s - loss: 0.0067 - acc: 0.9445 - val_loss: 0.1198 - val_acc: 0.6857\n",
      "Epoch 343/500\n",
      "0s - loss: 0.0075 - acc: 0.9440 - val_loss: 0.1126 - val_acc: 0.6757\n",
      "Epoch 344/500\n",
      "0s - loss: 0.0066 - acc: 0.9508 - val_loss: 0.1140 - val_acc: 0.6757\n",
      "Epoch 345/500\n",
      "0s - loss: 0.0068 - acc: 0.9459 - val_loss: 0.1152 - val_acc: 0.6817\n",
      "Epoch 346/500\n",
      "0s - loss: 0.0067 - acc: 0.9458 - val_loss: 0.1183 - val_acc: 0.6717\n",
      "Epoch 347/500\n",
      "0s - loss: 0.0074 - acc: 0.9401 - val_loss: 0.1142 - val_acc: 0.6767\n",
      "Epoch 348/500\n",
      "0s - loss: 0.0087 - acc: 0.9431 - val_loss: 0.1151 - val_acc: 0.6757\n",
      "Epoch 349/500\n",
      "0s - loss: 0.0080 - acc: 0.9434 - val_loss: 0.1164 - val_acc: 0.6727\n",
      "Epoch 350/500\n",
      "Epoch 00349: val_loss did not improve\n",
      "0s - loss: 0.0076 - acc: 0.9391 - val_loss: 0.1209 - val_acc: 0.6817\n",
      "Epoch 351/500\n",
      "0s - loss: 0.0064 - acc: 0.9464 - val_loss: 0.1235 - val_acc: 0.6807\n",
      "Epoch 352/500\n",
      "0s - loss: 0.0082 - acc: 0.9398 - val_loss: 0.1189 - val_acc: 0.6807\n",
      "Epoch 353/500\n",
      "0s - loss: 0.0076 - acc: 0.9394 - val_loss: 0.1138 - val_acc: 0.6907\n",
      "Epoch 354/500\n",
      "0s - loss: 0.0079 - acc: 0.9441 - val_loss: 0.1155 - val_acc: 0.6847\n",
      "Epoch 355/500\n",
      "0s - loss: 0.0079 - acc: 0.9471 - val_loss: 0.1189 - val_acc: 0.6887\n",
      "Epoch 356/500\n",
      "0s - loss: 0.0072 - acc: 0.9424 - val_loss: 0.1199 - val_acc: 0.6807\n",
      "Epoch 357/500\n",
      "0s - loss: 0.0072 - acc: 0.9398 - val_loss: 0.1223 - val_acc: 0.6607\n",
      "Epoch 358/500\n",
      "0s - loss: 0.0075 - acc: 0.9451 - val_loss: 0.1188 - val_acc: 0.6807\n",
      "Epoch 359/500\n",
      "0s - loss: 0.0066 - acc: 0.9459 - val_loss: 0.1200 - val_acc: 0.6767\n",
      "Epoch 360/500\n",
      "Epoch 00359: val_loss did not improve\n",
      "0s - loss: 0.0065 - acc: 0.9459 - val_loss: 0.1198 - val_acc: 0.6787\n",
      "Epoch 361/500\n",
      "0s - loss: 0.0073 - acc: 0.9455 - val_loss: 0.1122 - val_acc: 0.6827\n",
      "Epoch 362/500\n",
      "0s - loss: 0.0066 - acc: 0.9447 - val_loss: 0.1090 - val_acc: 0.6817\n",
      "Epoch 363/500\n",
      "0s - loss: 0.0071 - acc: 0.9455 - val_loss: 0.1139 - val_acc: 0.6867\n",
      "Epoch 364/500\n",
      "0s - loss: 0.0077 - acc: 0.9405 - val_loss: 0.1201 - val_acc: 0.6937\n",
      "Epoch 365/500\n",
      "0s - loss: 0.0065 - acc: 0.9445 - val_loss: 0.1190 - val_acc: 0.6987\n",
      "Epoch 366/500\n",
      "0s - loss: 0.0071 - acc: 0.9429 - val_loss: 0.1250 - val_acc: 0.6977\n",
      "Epoch 367/500\n",
      "0s - loss: 0.0068 - acc: 0.9445 - val_loss: 0.1203 - val_acc: 0.6907\n",
      "Epoch 368/500\n",
      "0s - loss: 0.0064 - acc: 0.9456 - val_loss: 0.1112 - val_acc: 0.6897\n",
      "Epoch 369/500\n",
      "0s - loss: 0.0074 - acc: 0.9443 - val_loss: 0.1085 - val_acc: 0.6857\n",
      "Epoch 370/500\n",
      "Epoch 00369: val_loss did not improve\n",
      "0s - loss: 0.0071 - acc: 0.9460 - val_loss: 0.1128 - val_acc: 0.6987\n",
      "Epoch 371/500\n",
      "0s - loss: 0.0067 - acc: 0.9463 - val_loss: 0.1217 - val_acc: 0.7027\n",
      "Epoch 372/500\n",
      "0s - loss: 0.0068 - acc: 0.9457 - val_loss: 0.1287 - val_acc: 0.7017\n",
      "Epoch 373/500\n",
      "0s - loss: 0.0067 - acc: 0.9428 - val_loss: 0.1270 - val_acc: 0.7127\n",
      "Epoch 374/500\n",
      "0s - loss: 0.0065 - acc: 0.9362 - val_loss: 0.1221 - val_acc: 0.6917\n",
      "Epoch 375/500\n",
      "0s - loss: 0.0064 - acc: 0.9457 - val_loss: 0.1232 - val_acc: 0.6997\n",
      "Epoch 376/500\n",
      "0s - loss: 0.0069 - acc: 0.9437 - val_loss: 0.1292 - val_acc: 0.7057\n",
      "Epoch 377/500\n",
      "0s - loss: 0.0083 - acc: 0.9445 - val_loss: 0.1244 - val_acc: 0.7007\n",
      "Epoch 378/500\n",
      "0s - loss: 0.0071 - acc: 0.9437 - val_loss: 0.1269 - val_acc: 0.7027\n",
      "Epoch 379/500\n",
      "0s - loss: 0.0075 - acc: 0.9451 - val_loss: 0.1231 - val_acc: 0.7027\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00379: val_loss did not improve\n",
      "0s - loss: 0.0068 - acc: 0.9435 - val_loss: 0.1214 - val_acc: 0.7007\n",
      "Epoch 381/500\n",
      "0s - loss: 0.0069 - acc: 0.9441 - val_loss: 0.1287 - val_acc: 0.7077\n",
      "Epoch 382/500\n",
      "0s - loss: 0.0065 - acc: 0.9484 - val_loss: 0.1252 - val_acc: 0.7007\n",
      "Epoch 383/500\n",
      "0s - loss: 0.0071 - acc: 0.9434 - val_loss: 0.1233 - val_acc: 0.7007\n",
      "Epoch 384/500\n",
      "0s - loss: 0.0075 - acc: 0.9526 - val_loss: 0.1261 - val_acc: 0.7117\n",
      "Epoch 385/500\n",
      "0s - loss: 0.0066 - acc: 0.9448 - val_loss: 0.1249 - val_acc: 0.7087\n",
      "Epoch 386/500\n",
      "0s - loss: 0.0071 - acc: 0.9391 - val_loss: 0.1213 - val_acc: 0.7167\n",
      "Epoch 387/500\n",
      "0s - loss: 0.0068 - acc: 0.9378 - val_loss: 0.1248 - val_acc: 0.7117\n",
      "Epoch 388/500\n",
      "0s - loss: 0.0071 - acc: 0.9440 - val_loss: 0.1215 - val_acc: 0.7077\n",
      "Epoch 389/500\n",
      "0s - loss: 0.0074 - acc: 0.9396 - val_loss: 0.1145 - val_acc: 0.7007\n",
      "Epoch 390/500\n",
      "Epoch 00389: val_loss did not improve\n",
      "0s - loss: 0.0060 - acc: 0.9484 - val_loss: 0.1081 - val_acc: 0.7017\n",
      "Epoch 391/500\n",
      "0s - loss: 0.0067 - acc: 0.9466 - val_loss: 0.1032 - val_acc: 0.7077\n",
      "Epoch 392/500\n",
      "0s - loss: 0.0072 - acc: 0.9429 - val_loss: 0.1057 - val_acc: 0.7067\n",
      "Epoch 393/500\n",
      "0s - loss: 0.0076 - acc: 0.9436 - val_loss: 0.0919 - val_acc: 0.6897\n",
      "Epoch 394/500\n",
      "0s - loss: 0.0073 - acc: 0.9433 - val_loss: 0.1021 - val_acc: 0.7057\n",
      "Epoch 395/500\n",
      "0s - loss: 0.0072 - acc: 0.9429 - val_loss: 0.1099 - val_acc: 0.6957\n",
      "Epoch 396/500\n",
      "0s - loss: 0.0073 - acc: 0.9396 - val_loss: 0.1124 - val_acc: 0.6977\n",
      "Epoch 397/500\n",
      "0s - loss: 0.0070 - acc: 0.9458 - val_loss: 0.1140 - val_acc: 0.7107\n",
      "Epoch 398/500\n",
      "0s - loss: 0.0072 - acc: 0.9471 - val_loss: 0.1117 - val_acc: 0.7097\n",
      "Epoch 399/500\n",
      "0s - loss: 0.0070 - acc: 0.9473 - val_loss: 0.1101 - val_acc: 0.7077\n",
      "Epoch 400/500\n",
      "Epoch 00399: val_loss did not improve\n",
      "0s - loss: 0.0071 - acc: 0.9506 - val_loss: 0.1099 - val_acc: 0.7027\n",
      "Epoch 401/500\n",
      "0s - loss: 0.0065 - acc: 0.9463 - val_loss: 0.1081 - val_acc: 0.7107\n",
      "Epoch 402/500\n",
      "0s - loss: 0.0066 - acc: 0.9499 - val_loss: 0.1050 - val_acc: 0.7077\n",
      "Epoch 403/500\n",
      "0s - loss: 0.0063 - acc: 0.9441 - val_loss: 0.1070 - val_acc: 0.7097\n",
      "Epoch 404/500\n",
      "0s - loss: 0.0070 - acc: 0.9469 - val_loss: 0.1033 - val_acc: 0.7037\n",
      "Epoch 405/500\n",
      "0s - loss: 0.0065 - acc: 0.9458 - val_loss: 0.1032 - val_acc: 0.7097\n",
      "Epoch 406/500\n",
      "0s - loss: 0.0068 - acc: 0.9470 - val_loss: 0.0924 - val_acc: 0.7117\n",
      "Epoch 407/500\n",
      "0s - loss: 0.0068 - acc: 0.9473 - val_loss: 0.0887 - val_acc: 0.7167\n",
      "Epoch 408/500\n",
      "0s - loss: 0.0061 - acc: 0.9431 - val_loss: 0.0926 - val_acc: 0.7077\n",
      "Epoch 409/500\n",
      "0s - loss: 0.0068 - acc: 0.9434 - val_loss: 0.0980 - val_acc: 0.7127\n",
      "Epoch 410/500\n",
      "Epoch 00409: val_loss did not improve\n",
      "0s - loss: 0.0072 - acc: 0.9518 - val_loss: 0.0993 - val_acc: 0.7027\n",
      "Epoch 411/500\n",
      "0s - loss: 0.0080 - acc: 0.9460 - val_loss: 0.1091 - val_acc: 0.7067\n",
      "Epoch 412/500\n",
      "0s - loss: 0.0066 - acc: 0.9485 - val_loss: 0.0969 - val_acc: 0.6997\n",
      "Epoch 413/500\n",
      "0s - loss: 0.0065 - acc: 0.9422 - val_loss: 0.0885 - val_acc: 0.7057\n",
      "Epoch 414/500\n",
      "0s - loss: 0.0062 - acc: 0.9430 - val_loss: 0.0901 - val_acc: 0.7077\n",
      "Epoch 415/500\n",
      "0s - loss: 0.0067 - acc: 0.9470 - val_loss: 0.0928 - val_acc: 0.7047\n",
      "Epoch 416/500\n",
      "0s - loss: 0.0067 - acc: 0.9490 - val_loss: 0.0931 - val_acc: 0.7087\n",
      "Epoch 417/500\n",
      "0s - loss: 0.0065 - acc: 0.9443 - val_loss: 0.0935 - val_acc: 0.7087\n",
      "Epoch 418/500\n",
      "0s - loss: 0.0065 - acc: 0.9474 - val_loss: 0.0853 - val_acc: 0.7077\n",
      "Epoch 419/500\n",
      "0s - loss: 0.0069 - acc: 0.9463 - val_loss: 0.0838 - val_acc: 0.7067\n",
      "Epoch 420/500\n",
      "Epoch 00419: val_loss did not improve\n",
      "0s - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0916 - val_acc: 0.7107\n",
      "Epoch 421/500\n",
      "0s - loss: 0.0064 - acc: 0.9446 - val_loss: 0.0942 - val_acc: 0.7047\n",
      "Epoch 422/500\n",
      "0s - loss: 0.0072 - acc: 0.9524 - val_loss: 0.0877 - val_acc: 0.7037\n",
      "Epoch 423/500\n",
      "0s - loss: 0.0065 - acc: 0.9397 - val_loss: 0.0839 - val_acc: 0.6977\n",
      "Epoch 424/500\n",
      "0s - loss: 0.0066 - acc: 0.9438 - val_loss: 0.0840 - val_acc: 0.7027\n",
      "Epoch 425/500\n",
      "0s - loss: 0.0061 - acc: 0.9448 - val_loss: 0.0876 - val_acc: 0.7037\n",
      "Epoch 426/500\n",
      "0s - loss: 0.0064 - acc: 0.9467 - val_loss: 0.0876 - val_acc: 0.7107\n",
      "Epoch 427/500\n",
      "0s - loss: 0.0066 - acc: 0.9489 - val_loss: 0.0911 - val_acc: 0.7137\n",
      "Epoch 428/500\n",
      "0s - loss: 0.0072 - acc: 0.9470 - val_loss: 0.0867 - val_acc: 0.7047\n",
      "Epoch 429/500\n",
      "0s - loss: 0.0069 - acc: 0.9508 - val_loss: 0.0812 - val_acc: 0.7047\n",
      "Epoch 430/500\n",
      "Epoch 00429: val_loss did not improve\n",
      "0s - loss: 0.0067 - acc: 0.9459 - val_loss: 0.0853 - val_acc: 0.7117\n",
      "Epoch 431/500\n",
      "0s - loss: 0.0062 - acc: 0.9436 - val_loss: 0.0841 - val_acc: 0.7097\n",
      "Epoch 432/500\n",
      "0s - loss: 0.0066 - acc: 0.9460 - val_loss: 0.0836 - val_acc: 0.7087\n",
      "Epoch 433/500\n",
      "0s - loss: 0.0058 - acc: 0.9401 - val_loss: 0.0819 - val_acc: 0.7067\n",
      "Epoch 434/500\n",
      "0s - loss: 0.0065 - acc: 0.9503 - val_loss: 0.0808 - val_acc: 0.7047\n",
      "Epoch 435/500\n",
      "0s - loss: 0.0071 - acc: 0.9504 - val_loss: 0.0742 - val_acc: 0.7077\n",
      "Epoch 436/500\n",
      "0s - loss: 0.0064 - acc: 0.9426 - val_loss: 0.0764 - val_acc: 0.7027\n",
      "Epoch 437/500\n",
      "0s - loss: 0.0065 - acc: 0.9496 - val_loss: 0.0741 - val_acc: 0.6967\n",
      "Epoch 438/500\n",
      "0s - loss: 0.0061 - acc: 0.9429 - val_loss: 0.0790 - val_acc: 0.6987\n",
      "Epoch 439/500\n",
      "0s - loss: 0.0065 - acc: 0.9441 - val_loss: 0.0807 - val_acc: 0.7087\n",
      "Epoch 440/500\n",
      "Epoch 00439: val_loss did not improve\n",
      "0s - loss: 0.0064 - acc: 0.9486 - val_loss: 0.0816 - val_acc: 0.7077\n",
      "Epoch 441/500\n",
      "0s - loss: 0.0062 - acc: 0.9402 - val_loss: 0.0743 - val_acc: 0.7057\n",
      "Epoch 442/500\n",
      "0s - loss: 0.0066 - acc: 0.9404 - val_loss: 0.0781 - val_acc: 0.7057\n",
      "Epoch 443/500\n",
      "0s - loss: 0.0065 - acc: 0.9445 - val_loss: 0.0862 - val_acc: 0.7007\n",
      "Epoch 444/500\n",
      "0s - loss: 0.0062 - acc: 0.9408 - val_loss: 0.0886 - val_acc: 0.7057\n",
      "Epoch 445/500\n",
      "0s - loss: 0.0060 - acc: 0.9468 - val_loss: 0.0874 - val_acc: 0.7027\n",
      "Epoch 446/500\n",
      "0s - loss: 0.0067 - acc: 0.9457 - val_loss: 0.0799 - val_acc: 0.7027\n",
      "Epoch 447/500\n",
      "0s - loss: 0.0069 - acc: 0.9358 - val_loss: 0.0765 - val_acc: 0.7007\n",
      "Epoch 448/500\n",
      "0s - loss: 0.0070 - acc: 0.9459 - val_loss: 0.0772 - val_acc: 0.7087\n",
      "Epoch 449/500\n",
      "0s - loss: 0.0065 - acc: 0.9465 - val_loss: 0.0820 - val_acc: 0.7147\n",
      "Epoch 450/500\n",
      "Epoch 00449: val_loss did not improve\n",
      "0s - loss: 0.0065 - acc: 0.9515 - val_loss: 0.0809 - val_acc: 0.7157\n",
      "Epoch 451/500\n",
      "0s - loss: 0.0066 - acc: 0.9500 - val_loss: 0.0793 - val_acc: 0.7117\n",
      "Epoch 452/500\n",
      "0s - loss: 0.0064 - acc: 0.9516 - val_loss: 0.0812 - val_acc: 0.7157\n",
      "Epoch 453/500\n",
      "0s - loss: 0.0071 - acc: 0.9470 - val_loss: 0.0804 - val_acc: 0.7057\n",
      "Epoch 454/500\n",
      "0s - loss: 0.0077 - acc: 0.9427 - val_loss: 0.0780 - val_acc: 0.7117\n",
      "Epoch 455/500\n",
      "0s - loss: 0.0061 - acc: 0.9495 - val_loss: 0.0849 - val_acc: 0.7157\n",
      "Epoch 456/500\n",
      "0s - loss: 0.0064 - acc: 0.9463 - val_loss: 0.0916 - val_acc: 0.7197\n",
      "Epoch 457/500\n",
      "0s - loss: 0.0062 - acc: 0.9490 - val_loss: 0.1056 - val_acc: 0.7377\n",
      "Epoch 458/500\n",
      "0s - loss: 0.0069 - acc: 0.9463 - val_loss: 0.1084 - val_acc: 0.7337\n",
      "Epoch 459/500\n",
      "0s - loss: 0.0063 - acc: 0.9524 - val_loss: 0.1068 - val_acc: 0.7267\n",
      "Epoch 460/500\n",
      "Epoch 00459: val_loss did not improve\n",
      "0s - loss: 0.0058 - acc: 0.9466 - val_loss: 0.0955 - val_acc: 0.7177\n",
      "Epoch 461/500\n",
      "0s - loss: 0.0068 - acc: 0.9437 - val_loss: 0.0955 - val_acc: 0.7307\n",
      "Epoch 462/500\n",
      "0s - loss: 0.0063 - acc: 0.9484 - val_loss: 0.0902 - val_acc: 0.7197\n",
      "Epoch 463/500\n",
      "0s - loss: 0.0062 - acc: 0.9444 - val_loss: 0.0952 - val_acc: 0.7227\n",
      "Epoch 464/500\n",
      "0s - loss: 0.0067 - acc: 0.9464 - val_loss: 0.0993 - val_acc: 0.7357\n",
      "Epoch 465/500\n",
      "0s - loss: 0.0063 - acc: 0.9409 - val_loss: 0.0946 - val_acc: 0.7157\n",
      "Epoch 466/500\n",
      "0s - loss: 0.0062 - acc: 0.9483 - val_loss: 0.0863 - val_acc: 0.7147\n",
      "Epoch 467/500\n",
      "0s - loss: 0.0060 - acc: 0.9451 - val_loss: 0.0855 - val_acc: 0.7157\n",
      "Epoch 468/500\n",
      "0s - loss: 0.0064 - acc: 0.9443 - val_loss: 0.0855 - val_acc: 0.7107\n",
      "Epoch 469/500\n",
      "0s - loss: 0.0066 - acc: 0.9449 - val_loss: 0.0907 - val_acc: 0.7167\n",
      "Epoch 470/500\n",
      "Epoch 00469: val_loss did not improve\n",
      "0s - loss: 0.0063 - acc: 0.9477 - val_loss: 0.0850 - val_acc: 0.7087\n",
      "Epoch 471/500\n",
      "0s - loss: 0.0060 - acc: 0.9502 - val_loss: 0.0834 - val_acc: 0.7117\n",
      "Epoch 472/500\n",
      "0s - loss: 0.0065 - acc: 0.9513 - val_loss: 0.0783 - val_acc: 0.7107\n",
      "Epoch 473/500\n",
      "0s - loss: 0.0063 - acc: 0.9485 - val_loss: 0.0809 - val_acc: 0.7107\n",
      "Epoch 474/500\n",
      "0s - loss: 0.0065 - acc: 0.9487 - val_loss: 0.0853 - val_acc: 0.7177\n",
      "Epoch 475/500\n",
      "0s - loss: 0.0067 - acc: 0.9486 - val_loss: 0.0840 - val_acc: 0.7177\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.0061 - acc: 0.9453 - val_loss: 0.0786 - val_acc: 0.7177\n",
      "Epoch 477/500\n",
      "0s - loss: 0.0054 - acc: 0.9463 - val_loss: 0.0751 - val_acc: 0.7117\n",
      "Epoch 478/500\n",
      "0s - loss: 0.0063 - acc: 0.9517 - val_loss: 0.0747 - val_acc: 0.7087\n",
      "Epoch 479/500\n",
      "0s - loss: 0.0071 - acc: 0.9489 - val_loss: 0.0717 - val_acc: 0.7037\n",
      "Epoch 480/500\n",
      "Epoch 00479: val_loss did not improve\n",
      "0s - loss: 0.0070 - acc: 0.9529 - val_loss: 0.0787 - val_acc: 0.7127\n",
      "Epoch 481/500\n",
      "0s - loss: 0.0071 - acc: 0.9480 - val_loss: 0.0792 - val_acc: 0.7137\n",
      "Epoch 482/500\n",
      "0s - loss: 0.0063 - acc: 0.9469 - val_loss: 0.0777 - val_acc: 0.7157\n",
      "Epoch 483/500\n",
      "0s - loss: 0.0064 - acc: 0.9497 - val_loss: 0.0734 - val_acc: 0.7117\n",
      "Epoch 484/500\n",
      "0s - loss: 0.0058 - acc: 0.9505 - val_loss: 0.0691 - val_acc: 0.7207\n",
      "Epoch 485/500\n",
      "0s - loss: 0.0071 - acc: 0.9475 - val_loss: 0.0739 - val_acc: 0.7177\n",
      "Epoch 486/500\n",
      "0s - loss: 0.0079 - acc: 0.9475 - val_loss: 0.0728 - val_acc: 0.7037\n",
      "Epoch 487/500\n",
      "0s - loss: 0.0076 - acc: 0.9397 - val_loss: 0.0760 - val_acc: 0.7187\n",
      "Epoch 488/500\n",
      "0s - loss: 0.0067 - acc: 0.9506 - val_loss: 0.0801 - val_acc: 0.7177\n",
      "Epoch 489/500\n",
      "0s - loss: 0.0063 - acc: 0.9467 - val_loss: 0.0752 - val_acc: 0.7177\n",
      "Epoch 490/500\n",
      "Epoch 00489: val_loss did not improve\n",
      "0s - loss: 0.0062 - acc: 0.9529 - val_loss: 0.0739 - val_acc: 0.7157\n",
      "Epoch 491/500\n",
      "0s - loss: 0.0057 - acc: 0.9420 - val_loss: 0.0677 - val_acc: 0.7147\n",
      "Epoch 492/500\n",
      "0s - loss: 0.0057 - acc: 0.9494 - val_loss: 0.0646 - val_acc: 0.7197\n",
      "Epoch 493/500\n",
      "0s - loss: 0.0062 - acc: 0.9458 - val_loss: 0.0634 - val_acc: 0.7187\n",
      "Epoch 494/500\n",
      "0s - loss: 0.0057 - acc: 0.9549 - val_loss: 0.0668 - val_acc: 0.7147\n",
      "Epoch 495/500\n",
      "0s - loss: 0.0059 - acc: 0.9506 - val_loss: 0.0699 - val_acc: 0.7087\n",
      "Epoch 496/500\n",
      "0s - loss: 0.0064 - acc: 0.9454 - val_loss: 0.0718 - val_acc: 0.7107\n",
      "Epoch 497/500\n",
      "0s - loss: 0.0060 - acc: 0.9458 - val_loss: 0.0734 - val_acc: 0.7107\n",
      "Epoch 498/500\n",
      "0s - loss: 0.0062 - acc: 0.9433 - val_loss: 0.0730 - val_acc: 0.7167\n",
      "Epoch 499/500\n",
      "0s - loss: 0.0059 - acc: 0.9515 - val_loss: 0.0714 - val_acc: 0.7117\n",
      "Epoch 500/500\n",
      "Epoch 00499: val_loss did not improve\n",
      "0s - loss: 0.0055 - acc: 0.9466 - val_loss: 0.0708 - val_acc: 0.7077\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "print('set up ANN')\n",
    "# ANN parameters\n",
    "dim_input = x_train.shape[1]\n",
    "dim_label = y_train.shape[1]\n",
    "n_neuron = 100\n",
    "batch_size = 512\n",
    "epochs = 500\n",
    "vsplit = 0.1\n",
    "batch_norm = True\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(dim_input,), dtype='float32')\n",
    "print(inputs.dtype)\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(n_neuron, name='1_base')(inputs)\n",
    "# x = BatchNormalization(axis=-1, name='1_base_bn')(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# less then 2 res_block, there will be variance\n",
    "x = res_block(x, n_neuron, stage=1, block='a', bn=batch_norm)\n",
    "x = res_block(x, n_neuron, stage=1, block='b', bn=batch_norm)\n",
    "\n",
    "# x = res_block(x, n_neuron, stage=1, block='c', bn=batch_norm)\n",
    "# x = res_block(x, n_neuron, stage=1, block='d', bn=batch_norm)\n",
    "\n",
    "predictions = Dense(dim_label, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# checkpoint (save the best model based validate loss)\n",
    "filepath = \"./tmp/weights.best.cntk.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             period=10)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=vsplit,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=True)\n",
    "\n",
    "model.load_weights(\"./tmp/weights.best.cntk.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2\n",
      "H\n",
      "O2\n",
      "OH\n",
      "O\n",
      "H2O\n",
      "HO2\n",
      "H2O2\n",
      "N2\n",
      "temperature\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_train)\n",
    "df_y_prdt = pd.DataFrame(data=predict, columns=output)\n",
    "\n",
    "error = (predict - y_train) / y_train\n",
    "df_error = abs(pd.DataFrame(data=error, columns=output))\n",
    "\n",
    "y_prdt_inv = []\n",
    "for itm in output:\n",
    "    print(itm)\n",
    "    out = label_norm_scalers[itm].inverse_transform(0.5 * (df_y_prdt[itm].values.reshape(-1, 1) + 1))\n",
    "    out = label_std_scalers[itm].inverse_transform(out)\n",
    "    y_prdt_inv.append(out)\n",
    "y_prdt_inv = np.concatenate(\n",
    "    y_prdt_inv,\n",
    "    axis=1\n",
    ")\n",
    "df_y_prdt_inv = pd.DataFrame(data=y_prdt_inv, columns=output)\n",
    "\n",
    "error_inv = (y_prdt_inv - train_new) / (train_new+1e-10)\n",
    "df_error_inv = abs(pd.DataFrame(data=error_inv, columns=output))\n",
    "\n",
    "\n",
    "def acc_plt(sp):\n",
    "    plt.figure()\n",
    "    plt.plot(train_new[sp],df_y_prdt_inv[sp],'kd',ms=1)\n",
    "    plt.axis('tight')\n",
    "    plt.axes().set_aspect('equal')\n",
    "    #plt.axis([train_new[sp].min(), train_new[sp].max(), train_new[sp].min(), train_new[sp].max()], 'tight')\n",
    "    plt.title(sp)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEICAYAAABBKnGGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b5bba019908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_plt('H2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAEICAYAAABS/TFyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b5be0535208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_plt('temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![haha](https://raw.githubusercontent.com/uqyge/cantera/master/img/imperial.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
